<body>

<h1 class="h1">Large-Scale Fine-Grained Building Classification for Semantic Urban Reconstruction</h1>

<p class="paraFirst">
    Buildings are essential components of urban areas. While research on the extraction and 3D reconstruction of buildings is widely conducted, information on the fine-grained roof types of buildings is usually ignored. This limits the potential of further analysis, e.g., in the context of urban planning applications. The fine-grained classification of building roof type from satellite images is a highly challenging task due to ambiguous visual features within the satellite imagery. The difficulty is further increased by the lack of corresponding fine-grained building classification datasets.
</p>
<p class="paraFirst">
    The 2023 IEEE GRSS Data Fusion Contest, organized by the Image Analysis and Data Fusion Technical Committee (IADF TC) of the IEEE Geoscience and Remote Sensing Society (GRSS), the Aerospace Information Research Institute under the Chinese Academy of Sciences, the Universität der Bundeswehr München, and GEOVIS Earth Technology Co., Ltd. aims to push current research on building extraction, classification, and 3D reconstruction towards urban reconstruction with fine-grained semantic information of roof types.
</p>
<p class="paraFirst">
    To this aim, the DFC23 establishes a large-scale, fine-grained, and multi-modal benchmark for the classification of building roof types. It consists of two challenging competition tracks investigating the fusion of optical and SAR data, while focusing on roof type classification and building height estimation, respectively.
</p>

<h2 style="color:black"> Track 1: Building Detection and Roof Type Classification</h2>
<p class="paraFirst">
    This track focuses on the detection and classification of building roof types from high-resolution satellite optical imagery and SAR images. The SAR and optical modalities are expected to provide complementary information. The given dataset covers senventeen cities worldwide across six continents. The classification task consists of 12 fine-grained, predefined roof types. Figure 1 shows an example.
    <center>
        <img src="https://drive.google.com/uc?export=view&id=1-BeMy6GqERgRspQhGyWhGmY8CioGhZVD" alt="cannot access google drive">
        <div style="border-bottom: 1px solid #d9d9d9;
        display: inline-block;
        color: #999;
        padding: 2px;">Figure 1: An example image tile of multi-modal data (optical and SAR) for building detection and roof type classification.</div>
    </center>
</p>

<h2 style="color: black;"> Track 2: Multi-Task Learning of Joint Building Extraction and Height Estimation</h2>
<p class="paraFirst">
    This track defines the joint task of building extraction and height estimation. Both are two very fundamental and essential tasks for building reconstruction. Same as in Track 1, the input data are multi-modal optical and SAR satellite imagery. Building extraction and height estimation from single-view satellite imagery depend on semantic features extracted from the imagery. Multi-task learning provides a potentially superior solution by reusing features and forming implicit constraints between multiple tasks in comparison to conventional separate implementations. Satellite images are provided with reference data, i.e., building annotations and normalized Digital Surface Models (nDSMs). The participants are required to reconstruct building heights and extract building footprints. Figure 2 shows an example.
    <center>
        <img src="https://drive.google.com/uc?export=view&id=1-C8rQ8QEgZIjfQsSOXa_D1DZ31GaOwgR" alt="cannot access google drive">
        <div style="border-bottom: 1px solid #d9d9d9;
        display: inline-block;
        color: #999;
        padding: 2px;">Figure 2: An example for joint building extraction and height estimation.</div>
    </center>
</p>

<h2 style="color: black;"> Results, Rewards and Prizes </h2>
<ul>
    <li>The first, second, third and fourth-ranked teams in each track will be declared as winners.</li>
    <li>The authors of the winning submissions will:
        <ul>
            <li>Present their approach in an invited session dedicated to the DFC23 at IGARSS 2023</li>
            <li>Publish their manuscripts in the Proceedings of IGARSS 2023</li>
            <li>Be awarded IEEE Certificates of Recognition</li>
        </ul>
    </li>
    <li>
        The first, second, and third-ranked teams of each track will receive $5,000, $2,000, and $1,000 (USD), respectively, as a cash prize.
    </li>
    <li>
        The authors of the first and second-ranked teams of each track will co-author a journal paper which will summarize the outcome of the DFC23 and will be submitted with open access to IEEE JSTARS.
    </li>
    <li>
        Top-ranked teams will be awarded during IGARSS 2023, Pasadena, USA in July 2023. 
    </li>
</ul>
<p class="paraFirst">
    The costs for open-access publication in JSTARS will be supported by the GRSS. The winner team prize is kindly sponsored by GEOVIS Earth Technology Co., Ltd.
</p>

<!-- <h2 style="color:black"> Citations </h2>
<p class="paraFirst">
    Any scientific publication using the data shall refer to the following paper:
    <ul>
        <li>
            [Huang et al., 2022] Huang, X., Ren, L., Liu, C., Wang, Y., Yu, H., Schmitt, M., Hänsch, R., Sun, X., Huang, H., Mayer, H., 2022. Urban Building Classification (UBC) – A Dataset for Individual Building Detection and Classification from Satellite Imagery. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 1413-1421.
        </li>
    </ul>
</p> -->

<h2 style="color:black"> Participation </h2>
<p class="paraFirst">
In order to participate:
<ul>
    <li>
        Create an account on Codalab
    </li>
    <li>
        Fill out this form in <a href="https://dfc.geovisearth.com/en/register?track=2" class="reference external">https://dfc.geovisearth.com/en/register?track=2</a>. The username and email in this form should be the same as your codalab account.
    </li>
    <li>
        Register under the <a href="#participate">Participate</a> tab.
    </li>
</ul>
Your requests will be approved within 24 hours.
</p>

<h2 style="color:black"> Acknowledgement </h2>
<p class="paraFirst">
    The IADF TC chairs would like to thank the Aerospace Information Research Institute under the Chinese Academy of Sciences, the Universität der Bundeswehr München, and GEOVIS Earth Technology Co., Ltd. for providing the data and the IEEE GRSS for continuously supporting the annual Data Fusion Contest through funding and resources.
</p>
<p class="paraFirst">
    The winners of the competition will receive a total of $16k as prizes, courtesy of GEOVIS Earth Technology Co., Ltd.
</p>

<!-- <img style="height: 100px;float: left;" src="https://drive.google.com/uc?export=view&id=1-HjEMf8bGtZXvH_xL2BEUsFKzJPfKKzv" alt="cannot access google drive">
<img style="height: 100px;float: left;" src="https://drive.google.com/uc?export=view&id=1-LOxhPFsKfo3hBTT5CP1th9Mut4kD2dZ" alt="cannot access google drive">
<img style="height: 100px;float: left;" src="https://drive.google.com/uc?export=view&id=1-IihYxL441_BBcm4PJyKX7F4pLzSpWhY" alt="cannot access google drive">
<img style="height: 100px;float: left;" src="https://drive.google.com/uc?export=view&id=1-OqRGPqJjIlPkQs7Pq0ysHHI5PSSDKJJ" alt="cannot access google drive">
<img style="height: 100px;float: left;" src="https://drive.google.com/uc?export=view&id=1-VS2aymzy0fHy_CeS8X0aSbUXGXESkdZ" alt="cannot access google drive"> -->


<a href="http://english.aircas.ac.cn/" style="text-decoration:none;">
    <img style="height: 100px;float: left;" src="https://drive.google.com/uc?export=view&id=1-HjEMf8bGtZXvH_xL2BEUsFKzJPfKKzv" alt="cannot access google drive">
</a>
<a href="https://www.unibw.de/" style="text-decoration:none;">
    <img style="height: 100px;float: left;" src="https://drive.google.com/uc?export=view&id=1-LOxhPFsKfo3hBTT5CP1th9Mut4kD2dZ" alt="cannot access google drive">
</a>
<a href="https://geovisearth.com/" style="text-decoration:none;">
    <img style="height: 100px;float: left;" src="https://drive.google.com/uc?export=view&id=1-IihYxL441_BBcm4PJyKX7F4pLzSpWhY" alt="cannot access google drive">
</a>
<a href="https://www.grss-ieee.org/" style="text-decoration:none;">
    <img style="height: 100px;float: left;" src="https://drive.google.com/uc?export=view&id=1-OqRGPqJjIlPkQs7Pq0ysHHI5PSSDKJJ" alt="cannot access google drive">
</a>
<a href="https://www.grss-ieee.org/technical-committees/image-analysis-and-data-fusion/" style="text-decoration:none;">
    <img style="height: 100px;float: left;" src="https://drive.google.com/uc?export=view&id=1-VS2aymzy0fHy_CeS8X0aSbUXGXESkdZ" alt="cannot access google drive">
</a>
</body>